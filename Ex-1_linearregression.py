# -*- coding: utf-8 -*-
"""Ex1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rZD6Pif-QM194BL-YhNk7fA1qbw21LUp

Investigate the feasibility and accuracy of predicting abalone age from physical measurements (length, diameter, height, weight) using a linear and logistic regression model constructed without the aid of external numerical libraries.
"""

import pandas as pd
import numpy as np

df = pd.read_csv("abalone.csv")

print(df.columns)

"""# LINEAR REGRESSION

Consider length as independent variable
"""

# independent variable
X = df['Length']

# dependent variable - convert to age
y = df['Rings'] + 1.5

"""step 1: compute mean"""

X_mean = X.mean()
y_mean = y.mean()

"""step 2: compute w1 (slope)"""

w1 = sum((X - X_mean)*(y - y_mean)) / sum((X - X_mean)**2)

"""step 3: compute w0 (intercept)"""

w0 = y_mean - (w1*X_mean)

"""step 4: predict values"""

y_pred = w0 + (w1*X)

"""step 5: calculate mean squared error"""

SSE = sum((y - y_pred)**2)
n = len(y)
MSE = SSE/n

print(f"Mean squared error of model w/ length as independent variable ={MSE:.2f}")

Xa = df["Diameter"]
Xb = df["Height"]
Xc = df["Whole weight"]

Xa_mean = Xa.mean()
Xb_mean = Xb.mean()
Xc_mean = Xc.mean()

w1_a = sum((Xa - Xa_mean)*(y - y_mean)) / sum((Xa - Xa_mean)**2)
w1_b = sum((Xb - Xb_mean)*(y - y_mean)) / sum((Xb - Xb_mean)**2)
w1_c = sum((Xc - Xc_mean)*(y - y_mean)) / sum((Xc - Xc_mean)**2)

w0_a = y_mean - (w1_a * Xa_mean)
w0_b = y_mean - (w1_b * Xb_mean)
w0_c = y_mean - (w1_c * Xc_mean)

y_predA = w0_a + (w1_a * Xa)
y_predB = w0_b + (w1_b * Xb)
y_predC = w0_c + (w1_c * Xc)

MSE_a = sum((y - y_predA**2))/n
MSE_b = sum((y - y_predB)**2)/n
MSE_c = sum((y - y_predC)**2)/n

print(f"Mean squared error of model w/ diameter as independent variable ={MSE_a:.2f}")
print(f"Mean squared error of model w/ height as independent variable ={MSE_b:.2f}")
print(f"Mean squared error of model w/ weight as independent variable ={MSE_c:.2f}")

"""1. Model Overview

- The study evaluates the feasibility of predicting Abalone age using Linear Regression, considering various physical measurements as independent variables. The model follows the standard regression equation: ð‘¦ =ð‘¤0 + ð‘¤1*ð‘‹

*   where ð‘‹ represents features like Length, Diameter, Height, and Whole Weight
*   and ð‘¦ is the predicted age (Rings + 1.5).

2. Key Performance Metric  
- Mean Squared Error (MSE)
MSE quantifies the average squared difference between actual and predicted values. A lower MSE indicates a better fit.

3. Interpretation of Results

- Best Predictor: The feature with the lowest MSE is the best predictor of Abalone age. (here : Height)

- Single Feature Limitation: Since all features yield high MSE values, using just one variable may not be sufficient for accurate predictions.

- Need for Improvement: A multiple regression model incorporating all features or a non-linear approach might improve accuracy.

# LOGISTIC REGRESSION
"""

def sigmoid(z):
  return 1 / (1 + np.exp(-z))

def trainLR(X, y, lr = 0.01, epochs = 1000): # lr is learning rate
  noRows = X.shape[0]
  X = np.c_[np.ones((noRows, 1)), X]  # 1ï¸âƒ£ adding bias term - concat a column of 1's to X
  m = len(y)

  # 2ï¸âƒ£ initialize weights to zero
  noCols = X.shape[1]
  weights = np.zeros(noCols)

  for _ in range(epochs): # 7ï¸âƒ£ Repeat Steps 3-6 for Multiple Epochs
    # @ means matrix multiplication
    z = X @ weights # 3ï¸âƒ£ compute linear combination z = w0 + w1X1 + w2X2 + ... + wnWn
    y_pred = sigmoid(z) # 4ï¸âƒ£ Apply Sigmoid Function
    weights -= (lr / m) * (X.T @ (y_pred - y)) # 5ï¸âƒ£ Compute Gradient and 6ï¸âƒ£ Update weights
  return weights

def predictLR(X, weights): #8ï¸âƒ£ Make Predictions with Trained Model
  noRows = X.shape[0]
  X = np.c_[np.ones((noRows, 1)), X]  # Correct way to add bias
  return (sigmoid(X @ weights) >= 0.5).astype(int)

def accuracy(y_true, y_pred):
  return (y_true == y_pred).mean() * 100

X = df[['Length']].values # 2d data
y = (df['Rings']+1.5 >= 10).astype(int) # convert output to 0's and 1's

# normalize
X = (X - X_mean)/X.std()

# train model
weights = trainLR(X,y)

# make predictions
y_pred = predictLR(X, weights)

# accuracy
acc = accuracy(y, y_pred)

# Print results
print("Weights:", weights)
print(f"Accuracy: {acc:.2f}%")